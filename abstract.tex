\begin{abstract}
SMARTeach addresses three pivotal visions in robotics: enabling robots to handle diverse objects in complex scenes, manipulate objects with varying geometries and physical properties, and interpret and follow intricate instruction manuals. While AI is predestined to realize these visions, its  promises to fulfill these visions have not been fully realized yet. Despite significant breakthroughs of AI in many domains, robotics has not seen a parallel surge, primarily due to challenges in task-specific data collection, the high demand for training data, and the extensive expertise required for applying AI in robotics.

Our innovative approach integrates intuitive data generation, fine-tuning of foundational knowledge, leveraging human feedback for continual self-improvement, and incorporating offline instructions with semantic and geometric information into skill, perception, and prediction models. Our objectives are to streamline the generation of human and synthetic data for robot learning, develop few-shot adaptable foundational representations, scale-up robot skill-learning capabilities, and enhance learning from interactive human feedback and offline instructions.

The project showcases its advancements through three use cases that mirror future industrial applications: sorting and disassembling a variety of Lego pieces, origami folding from visual instructions, and assembling complex Lego structures from unsorted pieces using instruction manuals. These cases highlight our approach's adaptability and potential for industrial application.

SMARTeach aims to revolutionize robotic skill, perception, and prediction models, significantly broadening the scope of robotic technology in various industries. This groundbreaking project lays the foundation for a new era of intelligent, adaptable, and user-friendly robotic solutions, set to rival human manipulation capabilities.
%SMARTeach addresses the crucial question of why AI breakthroughs in domains like natural language processing or image recognition have not been paralleled in robotics. This project confronts the key challenges limiting AI in robotics: the significant costs and complexities of collecting task-specific data, the demanding success rates required in industrial settings, and the extensive expertise needed to customize AI for particular robotic applications. Central to SMARTeach is the principle of 'instructability', which empowers robots to learn and adapt not only from real-time human feedback but also from offline sources such as instruction manuals.

%The project strategically aims to simplify data generation and annotation for complex tasks, thereby facilitating the broader application of advanced robotic manipulation. We will develop new intuitive data generation interfaces for generating demonstrations and scene annotations for complex manipulation tasks building on the latest augmented reality and teleoperation technologies. 
%The generated data will be utilized for continuous interactive refinement of robot perception, prediction, and skill models through diverse forms of human feedback, including demonstrations, pairwise comparisons, kinesthetic corrections, and verbal guidance. This continuous adaptation aims to reduce the need for human supervision progressively. Furthermore, the project focuses on integrating and fine-tuning foundational knowledge and instructional content to expedite the robot's task-specific learning processes.

%SMARTeach's approach involves scaling robot manipulation skills for complex scenarios, including environments with numerous intricate objects. We plan to develop novel object-centric skill representations that can adapt to new object arrangements and geometries. These representations will be learned from demonstrations and further refined via reinforcement learning in a data-efficient manner. Additionally, predictive models of object dynamics will be integrated into auto-generated physics simulations, enabling interactive pre-teaching of robot behavior in virtual environments before real-world application.

%Emphasizing instructability, interactive teaching, and the integration of varied learning paradigms, SMARTeach is poised to revolutionize robotics. The project targets high-impact use cases such as industrial assembly, sorting, and following instruction manuals such as origami folding or assembly of intricate structures, signaling a new era of intelligent, adaptable, and efficient robotic solutions.
\end{abstract}
